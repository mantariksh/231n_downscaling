{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, sampler, TensorDataset\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from scipy.interpolate import interp2d\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "import h5py\n",
    "\n",
    "from time import time\n",
    "\n",
    "from classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# From Assignment 2 PyTorch Notebook\n",
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 1\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '.'\n",
    "\n",
    "##########################################################################################\n",
    "#                                  BATCH_SIZE PARAMETER\n",
    "BATCH_SIZE = 1000\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "# sr_train = SR_Dataset(data_directory, train=TRAIN_MODE)\n",
    "# loader_train = DataLoader(sr_train, batch_size=BATCH_SIZE, \n",
    "#                           sampler=sampler.SubsetRandomSampler(range(TRAIN_FILES*YEARS_PER_FILE*IMGS_PER_YEAR)),\n",
    "#                          num_workers = 4)\n",
    "\n",
    "\n",
    "sr_val = SR_Dataset(data_directory, train=VAL_MODE)\n",
    "loader_val = DataLoader(sr_val, batch_size=BATCH_SIZE, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(VAL_FILES*YEARS_PER_FILE*IMGS_PER_YEAR)),\n",
    "                         num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape: (days, height, width). calculates rmse of each pixel.\n",
    "def rmse_pixel(gen, target):\n",
    "    return np.sqrt(np.mean(np.square(gen - target), axis = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y, y_pred: (N, C, H, W)\n",
    "def get_extremes(y, y_pred, quantiles, metric_fn):\n",
    "    output = np.zeros((2, len(quantiles), 2)) # channel, quantile, [mean/variance]\n",
    "    for q_index, q in enumerate(quantiles):\n",
    "        y_precip = y[:, 0, :, :]\n",
    "        y_pred_precip = y_pred[:, 0, :, :]\n",
    "        y_temp = y[:, 1, :, :]\n",
    "        y_pred_temp = y_pred[:, 1, :, :]\n",
    "        \n",
    "        H = y.shape[2]\n",
    "        W = y.shape[3]\n",
    "        # [precip|temp]_indices are (num_values*H*W, 3) arrays, where num_values is the number of values\n",
    "        # above this percentile, and the 3 columns correspodn to the three coordinates (see the for loops)\n",
    "        # below\n",
    "        precip_indices = np.array(np.where(y_precip > np.percentile(a = y_precip, q = q, axis = 0))).T\n",
    "        temp_indices = np.array(np.where(y_temp > np.percentile(a = y_temp, q = q, axis = 0))).T\n",
    "        num_values = int(precip_indices.shape[0] / (H * W)) + 1\n",
    "        y_precip_extreme = np.zeros((num_values, H, W))\n",
    "        y_pred_precip_extreme = np.zeros((num_values, H, W))\n",
    "        y_temp_extreme = np.zeros((num_values, H, W))\n",
    "        y_pred_temp_extreme = np.zeros((num_values, H, W))\n",
    "#         if num_values <= 2: continue\n",
    "        # coordinates aren't in order of pixel, so keep track of how many values we've layered\n",
    "        # for each pixel so far\n",
    "        counters = np.zeros((H, W), dtype = int)\n",
    "        for i, j, k in precip_indices:\n",
    "            y_precip_extreme[counters[j, k], j, k] = y_precip[i, j, k]\n",
    "            y_pred_precip_extreme[counters[j, k], j, k] = y_pred_precip[i, j, k]\n",
    "            counters[j, k] += 1\n",
    "        counters = np.zeros((H, W), dtype = int)\n",
    "        for i, j, k in temp_indices:\n",
    "            y_temp_extreme[counters[j, k], j, k] = y_temp[i, j, k]\n",
    "            y_pred_temp_extreme[counters[j, k], j, k] = y_pred_temp[i, j, k]\n",
    "            counters[j, k] += 1\n",
    "\n",
    "        metric_precip = metric_fn(y_precip_extreme, y_pred_precip_extreme)\n",
    "        metric_temp = metric_fn(y_temp_extreme, y_pred_temp_extreme)\n",
    "        output[0, q_index, 0] = np.mean(metric_precip)\n",
    "        output[0, q_index, 1] = np.var(metric_precip)\n",
    "        output[1, q_index, 0] = np.mean(metric_temp)\n",
    "        output[1, q_index, 1] = np.var(metric_temp)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G is generic for any image-generating model; could be SRCNN too\n",
    "def get_metrics(loader, G):\n",
    "    G = G.to(device=device)\n",
    "    G.eval() # set model to evaluation mode\n",
    "    \n",
    "    # initialize metrics\n",
    "    final_rmse = None\n",
    "    extreme_quantiles = [i / 10 for i in range(900, 1000, 5)]\n",
    "    extreme_metrics = [] # list will be populated with metrics from each batch\n",
    "    count = 0\n",
    "    \n",
    "    # calculate all metrics in one pass through val set\n",
    "    with torch.no_grad():\n",
    "        count = 0\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype) # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "            y_pred = G(x)\n",
    "            y = y.cpu().numpy()\n",
    "            y_pred = y_pred.cpu().numpy()\n",
    "            if final_rmse is not None:\n",
    "                final_rmse += rmse_pixel(y, y_pred)\n",
    "            else:\n",
    "                final_rmse = rmse_pixel(y, y_pred)\n",
    "            extreme_metrics.append(get_extremes(y, y_pred, extreme_quantiles, rmse_pixel))\n",
    "            count += 1\n",
    "            print('Done with batch %d.' % count)\n",
    "        final_rmse /= count\n",
    "        # num_batches, quantile, mean, variance\n",
    "        extreme_metrics = np.array(extreme_metrics)\n",
    "        # quantile, mean mean, mean variance\n",
    "        extreme_metrics = np.mean(extreme_metrics, axis = 0)\n",
    "    return final_rmse, extreme_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with batch 1.\n",
      "Done with batch 2.\n",
      "Done with batch 3.\n",
      "Done with batch 4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-80:\n",
      "Process Process-77:\n",
      "Process Process-78:\n",
      "Process Process-79:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f8918efcdd8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 347, in __del__\n",
      "    def __del__(self):\n",
      "  File \"/home/shared/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 2973) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-20ae9dd7e76f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SRGAN_G_06_05_best_precip.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfinal_rmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextreme_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-72-253f3039ec88>\u001b[0m in \u001b[0;36mget_metrics\u001b[0;34m(loader, G)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfinal_rmse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "G = Generator(num_channels=3)\n",
    "\n",
    "# Load the states from training on full dataset\n",
    "G.load_state_dict(torch.load('SRGAN_G_06_05_best_precip.pt'))\n",
    "\n",
    "final_rmse, extreme_metrics = get_metrics(loader_val, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
