{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, sampler, TensorDataset\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from scipy.interpolate import interp2d\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "import h5py\n",
    "\n",
    "from time import time\n",
    "\n",
    "################## LOGGING-BEGIN #########################\n",
    "import torchvision.utils as vutils\n",
    "from tensorboardX import SummaryWriter\n",
    "################## LOGGING-END ###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Assignment 2 PyTorch Notebook\n",
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/pytorch/vision/blob/master/torchvision/datasets/cifar.py\n",
    "\n",
    "HEIGHT_INDEX = 200\n",
    "WIDTH_INDEX = 200\n",
    "\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH = 64\n",
    "\n",
    "NUM_CHANNELS_IN = 2\n",
    "NUM_CHANNELS_OUT = 1\n",
    "\n",
    "TRAIN_FILES = 10\n",
    "VAL_FILES = 2\n",
    "TEST_FILES = 0\n",
    "YEARS_PER_FILE = 10\n",
    "IMGS_PER_YEAR = 365\n",
    "\n",
    "TRAIN_MODE = 0\n",
    "VAL_MODE = 1\n",
    "TEST_MODE = 2\n",
    "\n",
    "class SR_Dataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where directory\n",
    "            ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n",
    "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "            creates from test set.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "    base_folder = 'sr_data'\n",
    "    elevation_file = 'dem.pkl'\n",
    "    \n",
    "    train_list = np.array([\n",
    "        '1950s.hdf5',\n",
    "        '1960s.hdf5',\n",
    "        '1970s.hdf5',\n",
    "        '1980s.hdf5',\n",
    "        '1990s.hdf5',\n",
    "        '2000s.hdf5',\n",
    "        '2010s.hdf5',\n",
    "        '2020s.hdf5',\n",
    "        '2030s.hdf5',\n",
    "        '2040s.hdf5'\n",
    "    ])\n",
    "    \n",
    "    val_list = np.array([\n",
    "        '2050s.hdf5',\n",
    "        '2060s.hdf5'\n",
    "    ])\n",
    "\n",
    "    test_list = np.array([\n",
    "        \n",
    "    ])\n",
    "\n",
    "    def __init__(self, root, train=TRAIN_MODE):\n",
    "        \n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.train = train  # training set or val set or test set\n",
    "        \n",
    "        # load elevation data\n",
    "        fo_in = open(os.path.join(self.root, self.elevation_file), 'rb')\n",
    "        self.elevation = pickle.load(fo_in)\n",
    "        fo_in.close()\n",
    "        self.elevation = self.elevation[HEIGHT_INDEX:(HEIGHT_INDEX+IMG_HEIGHT), WIDTH_INDEX:(WIDTH_INDEX+IMG_WIDTH)]\n",
    "        elev_mean = np.mean(self.elevation)\n",
    "        elev_var = np.var(self.elevation)\n",
    "        self.elevation = (self.elevation - elev_mean) / np.sqrt(elev_var)\n",
    "        h,w=self.elevation.shape\n",
    "        self.elevation = self.elevation.reshape((1,h,w))\n",
    "\n",
    "    in_mean = np.array([1.9028055e-05])\n",
    "    in_var = np.array([1.5503707e-09])\n",
    "    out_mean = np.array([1.902273e-05])\n",
    "    out_var = np.array([2.3926674e-09])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (low_res, high_res)\n",
    "        \"\"\"\n",
    "        t1 = time()\n",
    "        file_idx = index // (YEARS_PER_FILE * IMGS_PER_YEAR)\n",
    "        img_in_file = index % (YEARS_PER_FILE * IMGS_PER_YEAR)\n",
    "        year_idx = img_in_file // IMGS_PER_YEAR\n",
    "        idx_in_year = img_in_file % IMGS_PER_YEAR\n",
    "        \n",
    "        f = None\n",
    "        if self.train == TRAIN_MODE:\n",
    "            f = h5py.File(os.path.join(self.base_folder, self.train_list[file_idx]), 'r')\n",
    "        elif self.train == VAL_MODE:\n",
    "            f = h5py.File(os.path.join(self.base_folder, self.val_list[file_idx]), 'r')\n",
    "        elif self.train == TEST_MODE:\n",
    "            f = h5py.File(os.path.join(self.base_folder, self.test_list[file_idx]), 'r')\n",
    "        \n",
    "        yr = list(f.keys())[year_idx]\n",
    "        pr =  f[yr]['pr'][idx_in_year]\n",
    "        f.close()\n",
    "        high_res = np.flip(pr[np.newaxis,:,:], axis=1)\n",
    "        high_res = high_res[:, HEIGHT_INDEX:(HEIGHT_INDEX+IMG_HEIGHT), WIDTH_INDEX:(WIDTH_INDEX+IMG_WIDTH)]\n",
    "\n",
    "        # get the input LR image from output HR image\n",
    "        c,h1,w1 = high_res.shape\n",
    "        blurred = np.zeros_like(high_res)\n",
    "        for i in range(c):\n",
    "            blurred[i,:,:] = gaussian_filter(high_res[i,:,:], 0.55)\n",
    "        half_res = blurred[:, ::2, ::2]\n",
    "        c,h2,w2 = half_res.shape\n",
    "        x = np.arange(h2)\n",
    "        y = np.arange(w2)\n",
    "        xnew = np.arange(0, h2, h2/h1)\n",
    "        ynew = np.arange(0, w2, w2/w1)\n",
    "        low_res = np.zeros_like(high_res)\n",
    "        for i in range(c):\n",
    "            f = RectBivariateSpline(x, y, half_res[i, :, :])\n",
    "            low_res[i, :, :] = f(xnew, ynew)\n",
    "            \n",
    "        low_res =  (low_res -  self.in_mean[:,np.newaxis,np.newaxis])  / np.sqrt(self.in_var[:,np.newaxis,np.newaxis])\n",
    "        high_res = (high_res - self.out_mean[:,np.newaxis,np.newaxis]) / np.sqrt(self.out_var[:,np.newaxis,np.newaxis])\n",
    "        \n",
    "        low_res = np.concatenate((low_res, self.elevation))\n",
    "        \n",
    "        low_res = torch.from_numpy(low_res)\n",
    "        high_res = torch.from_numpy(high_res)\n",
    "        \n",
    "        #print(time()-t1)\n",
    "        return low_res, high_res\n",
    "\n",
    "    def __len__(self):\n",
    "        print('not useful, fake!!!')\n",
    "        return 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        tmp = 'train' if self.train is True else 'test'\n",
    "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        tmp = '    Transforms (if any): '\n",
    "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        tmp = '    Target Transforms (if any): '\n",
    "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        return fmt_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '.'\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "sr_train = SR_Dataset(data_directory, train=TRAIN_MODE)\n",
    "loader_train = DataLoader(sr_train, batch_size=batch_size, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(TRAIN_FILES*YEARS_PER_FILE*IMGS_PER_YEAR)),\n",
    "                         num_workers = 4)\n",
    "\n",
    "sr_val = SR_Dataset(data_directory, train=VAL_MODE)\n",
    "loader_val = DataLoader(sr_val, batch_size=batch_size, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(VAL_FILES*YEARS_PER_FILE*IMGS_PER_YEAR)),\n",
    "                         num_workers = 4)\n",
    "\n",
    "#sr_val = SR_Dataset(data_directory, train=True, transform=transform, target_transform=transform)\n",
    "#loader_val = DataLoader(sr_val, batch_size=batch_size, \n",
    "#                        sampler=sampler.SubsetRandomSampler(range(TRAIN_SIZE, TRAIN_SIZE+VAL_SIZE)))\n",
    "\n",
    "#sr_test = SR_Dataset(data_directory, train=True, transform=transform)\n",
    "#loader_test = DataLoader(sr_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used https://github.com/togheppi/pytorch-super-resolution-model-collection/blob/master/srcnn.py to get basic idea\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, num_channels_in, num_channels_out, hidden_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential( # this is the original SRCNN from Dong et al. 2015\n",
    "            nn.ReplicationPad2d(4),\n",
    "            #nn.Conv2d(num_channels_in, hidden_channels, 9, padding=4),\n",
    "            nn.Conv2d(num_channels_in, hidden_channels, 9, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channels, hidden_channels//2, 1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.ReplicationPad2d(2),\n",
    "            #nn.Conv2d(hidden_channels//2, num_channels_out, 5, padding=2)\n",
    "            nn.Conv2d(hidden_channels//2, num_channels_out, 5, padding=0)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_SRCNN():\n",
    "    x = torch.zeros((64, NUM_CHANNELS_IN, IMG_HEIGHT, IMG_WIDTH), dtype=dtype)  # minibatch size 64, feature dimension 50\n",
    "    model = SRCNN(NUM_CHANNELS_IN, NUM_CHANNELS_OUT, 16)\n",
    "    scores = model(x)\n",
    "    print(scores.size())\n",
    "test_SRCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epoch(x, y_pred, y):\n",
    "    plt.figure(figsize=(16,12))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(x[0,0,:,:].cpu().detach().numpy())\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(y_pred[0,0,:,:].cpu().detach().numpy())\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(y[0,0,:,:].cpu().detach().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_loss, rmse_precip):\n",
    "    tcount = np.count_nonzero(train_loss)\n",
    "    \n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(range(tcount), train_loss[range(tcount)])\n",
    "    plt.title(\"SRCNN Loss\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(range(tcount), rmse_precip[range(tcount)])\n",
    "    plt.title(\"SRCNN Precipitation Loss\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## LOGGING-BEGIN #########################\n",
    "# how often to log images\n",
    "save_img_every = 500\n",
    "val_every = 200\n",
    "print_every = 200\n",
    "exp_name = 'experiments/train_SRCNN_preciponly_lr1e-4'\n",
    "writer = SummaryWriter(exp_name)\n",
    "################## LOGGING-END ###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_it(optimizer, model, num_epochs=1):\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    print(\"Expected num iters: \", len(loader_train)*epochs)\n",
    "    train_loss = np.zeros(len(loader_train)*num_epochs+1)\n",
    "    rmse_precip = np.zeros(len(loader_train)*num_epochs+1)\n",
    "    iter_count = 0\n",
    "    best_rmse_precip_val = 10000\n",
    "    tic = time()\n",
    "    for e in range(num_epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "\n",
    "            y_predicted = model(x)\n",
    "            loss_func = nn.MSELoss()\n",
    "            loss = loss_func(y_predicted, y)\n",
    "            train_loss[iter_count] = loss.item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            rmse_precip[iter_count] = torch.sqrt(torch.mean((y_predicted[:, 0, :, :] - y[:, 0, :, :]).pow(2)))\n",
    "\n",
    "            if iter_count % val_every == 0:\n",
    "                loss_total = 0 \n",
    "                rmse_precip_val = check_accuracy(loader_val, model)\n",
    "                if rmse_precip_val < best_rmse_precip_val:\n",
    "                    torch.save(model.cpu().state_dict(), 'training_SRCNN_06_05_preciponly_best_precip.pt')\n",
    "                    model = model.to(device=device)\n",
    "                    best_rmse_precip_val = rmse_precip_val\n",
    "                    \n",
    "                writer.add_scalars('Both precip RMSE',\n",
    "                                      {'Train': rmse_precip[iter_count],\n",
    "                                      'Val': rmse_precip_val}, iter_count)\n",
    "            \n",
    "            if iter_count % print_every == 0:\n",
    "                print('Epoch %d, Iteration %d, loss=%.4f, RMSEp=%.4f' % (e, t, loss.item(), \n",
    "                                                                                     rmse_precip[iter_count]))\n",
    "                plot_epoch(x, y_predicted, y)\n",
    "                plot_loss(train_loss, rmse_precip)\n",
    "                \n",
    "            if iter_count % save_img_every == 0:\n",
    "                # precip\n",
    "                input_precip_grid = vutils.make_grid(x[0, 0, :, :])\n",
    "                writer.add_image('Input precipitation', input_precip_grid, iter_count)\n",
    "                output_precip_grid = vutils.make_grid(y_predicted[0, 0, :, :])\n",
    "                writer.add_image('Output precipitation', output_precip_grid, iter_count)\n",
    "                true_precip_grid = vutils.make_grid(y[0, 0, :, :])\n",
    "                writer.add_image('True precipitation', true_precip_grid, iter_count)\n",
    "            \n",
    "            iter_count += 1\n",
    "                \n",
    "            del x, y, loss\n",
    "        torch.save(model.cpu().state_dict(), 'training_SRCNN_06_05_preciponly_checkpoint.pt')\n",
    "        model = model.to(device=device)\n",
    "        print('Epoch ', e, ' complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_baseline_accuracy(loader):\n",
    "    #if loader.dataset.train == TRAIN_MODE:\n",
    "    #    print('Checking accuracy on train set')\n",
    "    #elif loader.dataset.train == VAL_MODE:\n",
    "    #    print('Checking accuracy on validation set')\n",
    "    #elif loader.dataset.train == TEST_MODE:\n",
    "    #    print('Checking accuracy on test set')\n",
    "    count, rmse_precip_x = 0, 0, \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "            \n",
    "            # Normalize x to be in -1 to 1 for purpose of comparing with high res data in same range\n",
    "            # Turn it into a numpy array\n",
    "            x_np = x.numpy()\n",
    "            x_min = np.amin(x_np, axis=(2,3))[:, :, np.newaxis, np.newaxis]\n",
    "            x_max = np.amax(x_np, axis=(2,3))[:, :, np.newaxis, np.newaxis]\n",
    "            is_nan = np.int((x_min == x_max).any())\n",
    "            eps = 1e-9\n",
    "            x_norm_np = (x_np - x_min) / ((x_max - x_min + is_nan*eps) / 2) - 1\n",
    "            \n",
    "            x_norm = torch.from_numpy(x_norm_np)\n",
    "            x_norm = x_norm.to(device=device, dtype=dtype)\n",
    "            \n",
    "            rmse_precip_x += torch.sqrt(torch.mean((x_norm[:,0,:,:]-y[:,0,:,:]).pow(2)))\n",
    "            count += 1\n",
    "            \n",
    "        rmse_precip_x /= count\n",
    "        print('RMSEs: \\tInput precip: %.3f\\n' % \n",
    "              (rmse_precip_x))\n",
    "        \n",
    "    return rmse_precip_x\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    model = model.to(device=device)\n",
    "    model.eval() # set model to evaluation mode\n",
    "    count, rmse_precip = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype) # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "            \n",
    "            y_predicted = model(x)\n",
    "            rmse_precip += torch.sqrt(torch.mean((y_predicted[:,0,:,:]-y[:,0,:,:]).pow(2)))\n",
    "            count += 1\n",
    "            \n",
    "        rmse_precip /= count\n",
    "\n",
    "    return rmse_precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "epochs=20\n",
    "\n",
    "check_baseline_accuracy(loader_val)\n",
    "model = SRCNN(NUM_CHANNELS_IN, NUM_CHANNELS_OUT, 64)\n",
    "#model.load_state_dict(torch.load('training_SRCNN_checkpoint_crop.pt'))\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_it(optimizer, model, num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
